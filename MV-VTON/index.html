<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>MV-VTON</title>
    <link href="./MV_files/style.css" rel="stylesheet">
    <script type="text/javascript" src="./MV_files/jquery.mlens-1.0.min.js"></script>
    <script type="text/javascript" src="./MV_files/jquery.js"></script>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>

<body>

<div class="content">
    <h1><strong>MV-VTON: Multi-View Virtual Try-On with Diffusion Models</strong></h1>
    <p id="authors"><a href="https://github.com/hywang2002/">Haoyu Wang</a><sup style="margin-left: -7px;">1,2</sup><a
            href="https://scholar.google.com/citations?hl=en&user=8pIq2N0AAAAJ">Zhilu Zhang</a><sup
            style="margin-left: -7px;">1</sup><a
            href="https://scholar.google.com/citations?hl=en&user=L8tcNioAAAAJ">Donglin Di</a><a
            href="https://scholar.google.com/citations?hl=en&user=7phvKK4AAAAJ">Shiliang Zhang</a><sup
            style="margin-left: -7px;">2</sup><a
            href="https://scholar.google.com/citations?hl=en&user=rUOpCEYAAAAJ">Wangmeng Zuo</a><sup
            style="margin-left: -7px;">1</sup><br>
        <br>
        <!--        <span style="font-size: 24px">KAIST-->
        <span style="font-size: 20px;"><sup>1</sup>Harbin Institute of Technology, Harbin, China</span> <span
                style="font-size: 20px;"><sup>2</sup>Peking University, Beijing, China</span>
        </span></p>
    <br>
    <img src="./MV_files/cmp_1st_sv_2row.png" class="teaser-gif" style="width:100%;"><br>
    <font size="+2">
        <p style="text-align: center;font-size: 25px;">
            <a href="https://arxiv.org/abs/2312.01725" target="_blank">[Paper(coming soon)]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://github.com/hywang2002/MV-VTON" target="_blank">[Code]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="MV_files/bibtex.txt" target="_blank">[BibTeX(coming soon)]</a>
        </p>
    </font>
</div>


<div class="content">
    <h2>Abstract</h2>
    <p>The goal of image-based virtual try-on is to generate an image of the target person naturally wearing the given
        clothing. However, most existing methods solely focus on the frontal try-on using the frontal clothing. When the
        views of the clothing and person are significantly inconsistent, particularly when the person's view is
        non-frontal, the results are unsatisfactory. To address this challenge, we introduce
        <b>M</b>ulti-<b>V</b>iew <b>V</b>irtual <b>T</b>ry-<b>ON</b> <b>(MV-VTON)</b>, which aims to reconstruct the
        dressing results of a person from multiple views using the given clothes. On the one hand, given that
        single-view clothes provide insufficient information for MV-VTON, we instead employ two images, <i>i.e.</i>, the
        frontal and back views of the clothing, to encompass the complete view as much as possible. On the other hand,
        the
        diffusion models that have demonstrated superior abilities are adopted to perform our MV-VTON. In particular, we
        propose a view-adaptive selection method where hard-selection and soft-selection are applied to the global and
        local clothing feature extraction, respectively. This ensures that the clothing features are roughly fit to the
        person's view. Subsequently, we suggest a joint attention block to align and fuse clothing features with person
        features. Additionally, we collect a MV-VTON dataset, <i>i.e.</i>, <b>M</b>ulti-<b>V</b>iew <b>G</b>arment
        <b>(MVG)</b>, in which each person has multiple photos with diverse views and poses. Experiments show that the proposed
        method not only achieves state-of-the-art results on MV-VTON task using our MVG dataset, but also has
        superiority on frontal-view virtual try-on task using VITON-HD and DressCode datasets. Codes and datasets will
        be publicly released at <a
                href="https://github.com/hywang2002/MV-VTON">MV-VTON</a>.</p>
</div>

<!-- <div class="content">
  <h2>Background</h2>
  <p> Given a particular subject such as clock (shown in the real images on the left), it is very challenging to generate it in different contexts with state-of-the-art text-to-image models, while maintaining high fidelity to its key visual features. Even with dozens of iterations over a text prompt that contains a detailed description of the appearance of the clock (<em>"retro style yellow alarm clock with a white clock face and a yellow number three on the right part of the clock face in the jungle"</em>), the Imagen model [Saharia et al., 2022] can't reconstruct its key visual features (third column). Furthermore, even models whose text embedding lies in a shared language-vision space and can create semantic variations of the image, such as DALL-E2 [Ramesh et al., 2022], can neither reconstruct the appearance of the given subject nor modify the context (second column). In contrast, our approach (right) can synthesize the clock with high fidelity and in new contexts (<em>"a [V] clock in the jungle"</em>).</p>
  <br>
  <img class="summary-img" src="./StableVITON_files/background.png" style="width:100%;"> <br>
</div> -->

<div class="content">
    <h2>Method</h2>
    <p> (a) MV-VTON encodes frontal and back view clothing into global features using the CLIP image encoder and
        extracts multi-scale local features through U-Net encoder's trainable copy. Both features act as conditional
        inputs for the decoder of U-Net. Besides, both features are selectively extracted through view-adaptive
        selection mechanism. Specifically, hard-selection is performed on the clothing images under the frontal and
        back view, while (b) soft-selection modulates the clothing features on frontal and back view, respectively,
        based on the similarity between the clothing's pose and the person's pose. Then the features from both views are
        concatenated in the channel dimension.</p>
    <br>
    <img class="summary-img" src="./MV_files/framework.png" style="width:100%;"> <br>

    <p> Global clothing features \( c_g \) provide identical conditions for blocks at each scale of U-Net, and
        multi-scale
        local clothing features \( c_l \) allow for reconstructing more accurate details. Therefore, joint attention
        blocks are proposed to align \( c_g \) and \( c_l \) with the current person features. Additionally, to retain
        most of the semantic information in global features \( c_g \), we use local features \( c_l \) to refine some
        lost and
        erroneous detailed texture information in \( c_g \) by selective fusion.</p>
    <br>
    <img class="summary-img" src="./MV_files/jab.png" style="width:50%;"> <br>
</div>

<div class="content">
    <h2>Multi-View Results</h2>
    <p>We show multiple groups of try-on results for the same person under different views, using the proposed method.
        The first column displays frontal-view and back-view garments, the second to fourth columns depict persons from
        different views, and the fifth to seventh columns showcase the corresponding try-on results.</p>

    <div id="myCarousel2" class="carousel slide" data-ride="carousel">
        <!-- Indicators -->
        <ol class="carousel-indicators">
            <li data-target="#myCarousel2" data-slide-to="0" class="active"></li>
            <li data-target="#myCarousel2" data-slide-to="1"></li>
            <li data-target="#myCarousel2" data-slide-to="2"></li>
        </ol>

        <!-- Wrapper for slides -->
        <div class="carousel-inner">
            <div class="item active">
                <div class="carousel-caption-top">
                    <h1>Group 1 on MVG</h1>
                </div>
                <img src="./MV_files/mv_Page1.png" alt="Group 1 on MVG" style="width:100%;">
            </div>


            <div class="item">
                <div class="carousel-caption-top">
                    <h1>Group 2 on MVG</h1>
                </div>
                <img src="./MV_files/mv_Page2.png" alt="Group 2 on MVG" style="width:100%;">
            </div>

            <div class="item">
                <div class="carousel-caption-top">
                    <h1>Group 3 on MVG</h1>
                </div>
                <img src="./MV_files/mv_Page3.png" alt="Group 3 on MVG" style="width:100%;">
            </div>

        </div>

        <!-- Left and right controls -->
        <a class="left carousel-control" href="#myCarousel2" data-slide="prev">
            <span class="glyphicon glyphicon-chevron-left"></span>
            <span class="sr-only">Previous</span>
        </a>
        <a class="right carousel-control" href="#myCarousel2" data-slide="next">
            <span class="glyphicon glyphicon-chevron-right"></span>
            <span class="sr-only">Next</span>
        </a>
    </div>

    <br>
    <br>
    <br>
    <br>

    <h2>High Resolution Results</h2>
    <p>We present more results at 1024×768 resolution on VITON-HD and DressCode datasets utilizing the model trained at
        512×384 resolution.</p>
    <center>
        <div id="myCarousel" class="carousel slide" data-ride="carousel">
            <!-- Indicators -->
            <ol class="carousel-indicators">
                <li data-target="#myCarousel" data-slide-to="0" class="active"></li>
                <li data-target="#myCarousel" data-slide-to="1"></li>
                <li data-target="#myCarousel" data-slide-to="2"></li>
                <li data-target="#myCarousel" data-slide-to="3"></li>
            </ol>

            <!-- Wrapper for slides -->
            <div class="carousel-inner">
                <div class="item active">
                    <img src="./MV_files/high1.png" alt="High Resolution Results" style="width:100%;">
                </div>

                <div class="item">
                    <img src="./MV_files/high2.png" alt="High Resolution Results" style="width:100%;">
                </div>

                <div class="item">
                    <img src="./MV_files/high3.png" alt="High Resolution Results" style="width:100%;">
                </div>

                <div class="item">
                    <img src="./MV_files/high4.png" alt="High Resolution Results" style="width:100%;">
                </div>

            </div>

            <!-- Left and right controls -->
            <a class="left carousel-control" href="#myCarousel" data-slide="prev">
                <span class="glyphicon glyphicon-chevron-left"></span>
                <span class="sr-only">Previous</span>
            </a>
            <a class="right carousel-control" href="#myCarousel" data-slide="next">
                <span class="glyphicon glyphicon-chevron-right"></span>
                <span class="sr-only">Next</span>
            </a>
        </div>
    </center>

    <br>
    <br>
    <br>
    <br>

    <h2>Qualitative Comparisons</h2>
    <center>
        <div id="myCarousel3" class="carousel slide" data-ride="carousel">
            <!-- Indicators -->
            <ol class="carousel-indicators">
                <li data-target="#myCarousel3" data-slide-to="0" class="active"></li>
                <li data-target="#myCarousel3" data-slide-to="1"></li>
                <li data-target="#myCarousel3" data-slide-to="2"></li>
                <li data-target="#myCarousel3" data-slide-to="3"></li>
            </ol>

            <!-- Wrapper for slides -->
            <div class="carousel-inner">
                <div class="item active">
                    <div class="carousel-caption-top">
                        <h1>MVG</h1>
                    </div>
                    <img src="./MV_files/cmp_Page1.png" alt="MVG" style="width:100%;">
                </div>

                <div class="item">
                    <div class="carousel-caption-top">
                        <h1>VITON-HD</h1>
                    </div>
                    <img src="./MV_files/cmp_Page2.png" alt="VITON-HD" style="width:100%;">
                </div>

                <div class="item">
                    <div class="carousel-caption-top">
                        <h1>DressCode</h1>
                    </div>
                    <img src="./MV_files/cmp_Page3.png" alt="DressCode" style="width:100%;">
                </div>

                <div class="item">
                    <div class="carousel-caption-top">
                        <h1>DressCode</h1>
                    </div>
                    <img src="./MV_files/cmp_Page4.png" alt="DressCode" style="width:100%;">
                </div>

            </div>

            <!-- Left and right controls -->
            <a class="left carousel-control" href="#myCarousel3" data-slide="prev">
                <span class="glyphicon glyphicon-chevron-left"></span>
                <span class="sr-only">Previous</span>
            </a>
            <a class="right carousel-control" href="#myCarousel3" data-slide="next">
                <span class="glyphicon glyphicon-chevron-right"></span>
                <span class="sr-only">Next</span>
            </a>
        </div>
    </center>

    <br>
    <br>
    <br>

    <!--    <h2>Demo Video</h2>-->
    <!--    <center>-->
    <!--        <iframe width="800" height="450" src="https://www.youtube.com/embed/x3k4u7F4ReA?si=be41wCZuYsUhyvwY"-->
    <!--                title="YouTube video player" frameborder="0"-->
    <!--                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"-->
    <!--                allowfullscreen></iframe>-->
    <!--    </center>-->
</div>

<div class="content">
    <h2>Model Weights</h2>
    You can download it from <a
        href="https://github.com/hywang2002/MV-VTON">link</a>.
</div>

<div class="content">
    <h2>BibTex</h2>
    <code> @article{kim2023stableviton,<br>
        &nbsp;&nbsp;title={MV-VTON: Multi-View Virtual Try-On with Diffusion Models (Continuously updating ...)},<br>
        &nbsp;&nbsp;author={Kim, Jeongho and Gu, Gyojung and Park, Minho and Park, Sunghyun and Choo, Jaegul},<br>
        &nbsp;&nbsp;journal={arXiv preprint arXiv:2312.01725},<br>
        &nbsp;&nbsp;year={2023}<br>
        } </code>
</div>

<!-- <div class="content" id="acknowledgements">
  <p><strong>Acknowledgements</strong>:
    Sunghyun Park is the corresponding author.
  </p>
</div> -->

<!-- <div class="content">
    <h2>Acknowledgements</h2>
    <p>Sunghyun Park is the corresponding author.</p>
  </div> -->

<div class="content">
    <p class="serif">
        Project page template is borrowed from <a href="https://dreambooth.github.io/">DreamBooth</a> and <a
            href="https://rlawjdghek.github.io/StableVITON/">StableVITON</a>.<br>
<!--        <strong>Acknowledgements.</strong> Sunghyun Park is the corresponding author.-->
    </p>
</div>

</body>
</html>
